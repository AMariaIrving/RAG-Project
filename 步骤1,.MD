

### `run_stage_1.py` 内部逻辑的超详细设计

**脚本总体目标:** 将 `/00_input/` 文件夹内的原始、多模态、非结构化信息，转化为一份位于 `/01_stage_discovery/` 文件夹下的、结构清晰、包含深度洞察的《情境化需求分析报告》（`c_contextualized_req_report.txt`）。

---

#### **步骤 1: 环境初始化与输入读取 (Setup & Ingestion)**

*   **功能描述:** 脚本启动后，首先准备好工作环境，然后全面地、智能地读取所有输入源。
*   **详细流程:**
    1.  **路径定义:** 脚本内部硬编码或通过配置文件定义输入路径 (`../00_input/`) 和输出路径 (`../01_stage_discovery/`)。
    2.  **输出目录检查:** 检查输出路径是否存在，如果不存在，则创建该文件夹。确保后续文件写入不会失败。
    3.  **输入文件遍历:** 脚本开始遍历输入路径下的所有文件和子文件夹。
    4.  **智能内容提取:** 针对不同文件类型，执行不同的处理逻辑：
        *   **对于 `.txt`, `.md`, `.docx` 文件:** 调用相应的库（如 `python-docx`）直接提取纯文本内容。
        *   **对于 `.pdf` 文件:** 调用PDF处理库（如 `PyMuPDF`）提取文本。需要考虑PDF是文本型还是扫描图片型。
        *   **对于 `.jpg`, `.png`, `.webp` 文件:** 记录下这些图片文件的**本地路径**。我们不会提取图片内容，而是准备将路径或图片本身传递给多模态模型。
        *   **对于 `.mp3`, `.wav`, `.m4a` 音频文件:** 调用一个本地或云端的**语音转文本(ASR)服务**（例如 `Whisper` API），将音频内容转换为文本。
        *   **对于 `.mp4`, `.mov` 视频文件:** 先提取其音轨，然后同样调用ASR服务进行转录。
    5.  **内容聚合:** 将所有从不同来源提取到的文本内容，合并成一个大的文本块。为了保留上下文，可以在每个文档的文本前后加上标记，例如：
        > ```
        > --- START OF DOCUMENT: interview_notes.txt ---
        > [访谈记录的全部文本内容]
        > --- END OF DOCUMENT: interview_notes.txt ---
        >
        > --- START OF DOCUMENT: audio_transcript_meeting_20251011.txt ---
        > [会议录音转录的全部文本内容]
        > --- END OF DOCUMENT: audio_transcript_meeting_20251011.txt ---
        > ```
    6.  **数据暂存:** 将聚合后的文本块存储在一个变量中，将所有图片文件的路径列表存储在另一个变量中。

---

#### **步骤 2: 首次LLM调用 - 原始信息摘要 (Initial LLM Call - Raw Info Summarization)**

*   **功能描述:** 调用多模态大语言模型，对所有原始信息进行第一次的理解、消化和提炼，形成一份干净、集中的摘要。
*   **详细流程:**
    1.  **Prompt构建:** 精心设计一个Prompt模板，该模板将包含以下部分：
        *   **角色扮演:** "你是一位经验丰富的业务分析师，你的任务是阅读并理解以下所有关于某家公司的原始资料。"
        *   **任务指令:** "请你将所有文本和图片信息进行综合，然后生成一份结构化的'原始信息摘要'。摘要需要清晰地罗列出公司的基本情况、主要业务流程、以及在资料中被明确提及的问题点或目标。不要进行任何推理或添加外部信息，严格基于我提供的内容。"
        *   **数据注入:**
            *   将【步骤1】中聚合的文本块，插入到Prompt的指定位置。
            *   将【步骤1】中收集的图片文件（或它们的Base64编码），按照多模态API的要求，附加到Prompt中。
    2.  **API调用:** 将构建好的完整Prompt（包含文本和图片），**调用一次**多模态大语言模型（MOE/LLM）的API。
    3.  **结果处理与保存:**
        *   接收API返回的文本内容。
        *   执行基本的清洗（例如去除不必要的空格）。
        *   将清洗后的文本，作为《原始信息摘要》，写入到文件 `/01_stage_discovery/a_raw_info_summary.txt` 中。

---

#### **步骤 3: RAG调用 - 宏观情境检索 (RAG Call - Macro Context Retrieval)**

*   **功能描述:** 基于初步的摘要，从外部知识库中检索相关的宏观背景信息，为深度分析提供“情境”。
*   **详细流程:**
    1.  **关键词提取:**
        *   **方式A (简单):** 脚本直接读取 `a_raw_info_summary.txt` 文件内容。
        *   **方式B (更智能):** 再次**调用一次LLM**（一个轻量级、快速的模型即可），给它摘要文本并指示：“请从以下文本中提取出最关键的实体和主题词，用于后续的资料检索。例如：公司所在的行业、地理位置、核心产品、提到的技术术语、描述的主要问题等。请以逗号分隔的列表形式返回。”
    2.  **并行检索:** 脚本遍历提取出的每一个关键词或主题（例如：“家电制造”, “广东佛山”, “供应链牛鞭效应”, “工业4.0”）。对于**每一个关键词**，都**独立地调用一次RAG系统的查询接口**。这些调用可以设计成并行执行以提高效率。
    3.  **结果汇总与去重:**
        *   收集所有RAG调用返回的文档片段。
        *   由于不同的关键词可能检索到相同的文档片段，需要实现一个去重逻辑（例如，基于文档ID或内容的哈希值）。
    4.  **格式化保存:** 将去重、汇总后的所有RAG结果，格式化后写入文件 `/01_stage_discovery/b_macro_context_report.txt`。为了可追溯性，每个片段前最好都标注上它是通过哪个关键词检索到的。

---

#### **步骤 4: 二次LLM调用 - 综合分析与报告生成 (Second LLM Call - Synthesis & Report Generation)**

*   **功能描述:** 这是模块一的收官之作。融合内部信息（摘要）和外部信息（情境报告），进行深度推理，生成最终的、富有洞察力的分析报告。
*   **详细流程:**
    1.  **上下文准备:** 脚本同时读取 `a_raw_info_summary.txt` 和 `b_macro_context_report.txt` 的全部内容。
    2.  **终极Prompt构建:** 设计一个更为复杂的Prompt模板，扮演“战略顾问”的角色。
        *   **角色扮演:** "你是一位顶级的制造业战略咨询顾问，擅长将企业的内部问题与宏观的行业、政策环境相结合，发现深层次的机会与挑战。"
        *   **上下文注入:**
            *   "【内部资料摘要】:\n[此处插入 a_...summary.txt 的全部内容]"
            *   "【外部情境参考】:\n[此处插入 b_...report.txt 的全部内容]"
        *   **核心任务指令:** "请你基于以上内部和外部信息，撰写一份《情境化需求分析报告》。报告需要包含以下部分：1. 对公司显性需求的总结（直接从内部资料中提炼）。2. 结合外部情境，分析并生成公司的隐性或派生需求（必须解释你的推理过程，例如'因为外部政策要求XX，所以该公司隐含了XX需求'）。3. 识别出潜在的机会点和风险点。你的分析必须深入、有逻辑，语言要专业。"
    3.  **API调用:** 将这个包含了丰富上下文的终极Prompt，**调用一次**强大的MOE/LLM API。
    4.  **最终输出保存:**
        *   接收API返回的最终报告文本。
        *   将其写入最终产物文件 `/01_stage_discovery/c_contextualized_req_report.txt`。

---
